# Requirements Prompt: Computer Opponent (AI) Levels 1–3 for Terminal Checkers

## Scope
Add a “play vs computer” mode on top of the existing terminal checkers game. This work adds **AI move selection logic** only. It must reuse the existing game engine capabilities for:

- Enumerating legal moves for a side
- Applying a move to a game state
- Detecting captures / kinging / end-of-turn state as already implemented

No UI redesign is required beyond “computer is thinking…” and showing the chosen move, unless your game already has a standard way to display moves.

---

## Common Requirements (Applies to Levels 1–3)

### A) Inputs and Outputs
- The AI module must accept:
  - Current game state (board + side-to-move + any rule state needed to determine legal moves)
  - The side the AI controls (e.g., black or red)
  - A difficulty/AI level selector (`1`, `2`, or `3`)
- The AI module must output:
  - One chosen **legal move** in the game’s existing move representation

### B) Legal Move Source of Truth
- The AI must select **only** from the legal moves produced by the game engine.
- If the engine already enforces “must-capture” rules, the AI must respect that (because the legal move list will already reflect it).
- If the engine does **not** enforce “must-capture,” Level 1 and above still apply *preference logic* (see below) but must not invent moves.

### C) Determinism and Randomness
- The AI must support both:
  - **Deterministic tie-breaking** (stable results given the same state), and
  - **Optional randomness** (for variety)
- If randomness is enabled, the AI must support a seedable RNG so results are reproducible for demos/tests.

### D) Failure Mode
- If there are **no legal moves**, AI must return “no move” (or a null/empty result consistent with the engine), and the game should treat that as a loss/terminal condition per existing rules.

---

## Level 1 — Capture-First Selector

### Goal
Make the computer opponent feel immediately competent with minimal complexity.

### Requirements
1. **Generate all legal moves** for the AI-controlled side.
2. Partition moves into:
   - `capture_moves`: moves that capture at least one opponent piece
   - `non_capture_moves`: all other legal moves
3. Selection behavior:
   - If `capture_moves` is non-empty: choose a move from `capture_moves`
   - Else: choose a move from `non_capture_moves`
4. Tie-breaking:
   - If deterministic mode: select the first move according to a stable ordering (e.g., sorted by from-square then to-square)
   - If random mode: select uniformly at random among the candidate set

### Notes / Non-goals
- Level 1 does not evaluate safety or future consequences.
- If multi-capture sequences are represented as a single move by the engine, Level 1 treats them normally.
- If the engine requires “continue jumping,” Level 1 must operate at each decision point using the engine’s legal move list for that sub-turn state.

---

## Level 2 — Heuristic Scoring (1-Ply Evaluation)

### Goal
Choose moves using a lightweight evaluation function: “pick the move that makes the position better right now.”

### Requirements
1. **Generate all legal moves** for the AI-controlled side.
2. For each legal move `m`:
   - Compute `next_state = apply_move(current_state, m)`
   - Compute a numeric `score(m)` using the heuristic rules below
3. Choose the move with the **highest score**.
4. Tie-breaking:
   - Deterministic: stable ordering
   - Random: uniform random among best-scoring moves (seedable)

### Required Heuristic Components (language-agnostic)
The scoring function must be configurable via weights, with sensible defaults. At minimum include:

**H1) Material gain**
- Positive score for capturing pieces:
  - `+W_capture * (number_of_pieces_captured_by_move)`
- If piece types differ (men vs kings), allow:
  - `+W_capture_man` and `+W_capture_king` (optional if your engine can detect it)

**H2) Kinging bonus**
- If the move results in the moved piece becoming a king, add:
  - `+W_king`

**H3) Immediate vulnerability penalty**
- If, after applying the move, the moved piece can be captured immediately on the opponent’s next turn (based on opponent legal moves from `next_state`):
  - `-W_hang`
- If you can measure severity (e.g., moved piece can be captured by multiple replies or by a multi-capture), increase penalty proportionally (optional).

**H4) Progress / positioning bonus (optional but recommended)**
- Small bonus for advancing a man toward promotion, or for occupying safer squares (edges/corners), if your rules/board make that meaningful.
  - Examples:
    - `+W_advance` for moving a man forward
    - `+W_edge` for landing on an edge square

### Notes / Non-goals
- Level 2 is “1-ply”: it evaluates only the **immediate** resulting position, not the opponent’s best response, except as needed for the vulnerability check (H3).

---

## Level 3 — Simple Lookahead (2-Ply: AI move, then opponent best reply)

### Goal
Avoid obvious blunders by simulating “If I do this, what’s the best thing the opponent can do next?”

### Requirements
1. **Generate all legal moves** for the AI-controlled side.
2. For each AI candidate move `m`:
   - Compute `state1 = apply_move(current_state, m)`
   - Generate all legal opponent replies from `state1`: `opp_moves = legal_moves(state1, opponent_side)`
   - If `opp_moves` is empty:
     - Treat as a terminal favorable result (win) and prefer this move strongly (e.g., assign very high score)
3. For each opponent reply `r` in `opp_moves`:
   - Compute `state2 = apply_move(state1, r)`
   - Evaluate `state2` using the **same heuristic evaluation** used in Level 2, from the AI’s perspective (material/kinging/position, etc.)
4. Assume the opponent plays optimally:
   - Compute `worst_case_score(m) = MIN over r of eval(state2)`
5. Choose the AI move `m` that **maximizes** `worst_case_score(m)` (a minimax depth-2 step).

### Tie-breaking
- Deterministic: stable ordering among equal scores
- Random: uniform random among best moves (seedable)

### Performance Requirements
- Must remain responsive for a terminal game.
- If branching is high, the implementation may:
  - Cap the number of opponent replies analyzed (e.g., analyze the top N replies by a quick heuristic), **or**
  - Enforce a time budget and stop evaluating additional replies when exceeded
- Any cap/time budget must be configurable and must default to “safe for interactive play.”

### Notes / Non-goals
- This is not full minimax to multiple depths. It is intentionally limited to 2-ply for simplicity and speed.
- Alpha-beta pruning is not required at Level 3.

---

## Acceptance Criteria (All Levels)
- The AI never selects an illegal move.
- For a given state:
  - Level 1 always prefers capture moves when available.
  - Level 2 selects a move that maximizes the defined heuristic score.
  - Level 3 selects a move that maximizes the score after considering the opponent’s best reply (2-ply minimax).
- With deterministic mode enabled, the AI returns the same move every time for the same state.
